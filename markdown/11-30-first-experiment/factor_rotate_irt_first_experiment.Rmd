---
title: "Factor Rotate (SS_IRB) IRT First Experiment"
author: "Jiguang Li"
date: "`r format(Sys.time(), '%y-%m-%d')`"
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_depth: 2
    number_sections: true
    df_print: paged
params:
  config_filepath: "/Users/jiguangli/IBP_IRT/config/dataconfig.yaml"
---

**Main Takeaways**

I tried to fit both synthetic and real binary item response data to the Factor Rotate code (truncation level = 4), and compare the results with the standard MIRT models. 

- **Experiments on 3 synthetic datasets** (section 1): 

  - **Sparser Factor Loading:** We can see the factor rotate model tends to generate more sparse factor loading compared to the standard MIRT model. At truncation level 4, the number of factors identified by the SS-IBP prior are close to the true number of factor loadings per question.
  - **Insample Goodness-of-fit: ** The factor rotate model has slightly higher MSE compared to the MIRT models for the 3 synthetic datasets. This is expected because these synthetic datasets are generated from the  Two Parameter Logistic IRT Model formulation.
  
- **Experiments on real dataset (section 2)**: both the MIRT models and the factor rotate models suggest there may be only one latent factor for the real dataset. Both models have very similar MSE. 

```{r, echo=FALSE, warning=FALSE}
library(pacman)
p_load("tidyverse", "argparser", "feather",  "magic", "hash" , "pander", "knitr", "dplyr",  "plotmo", "caret",  "cvms", "magrittr", "arrow", "yaml", "plot.matrix")
config_filepath <- "/Users/jiguangli/IBP_IRT/config/data_config.yaml"
config <- read_yaml(config_filepath)
```

We fit binary item response data using the factor rotate example code, and compare its results with the baseline 2PL MIRT models

## Experiment on Fake Data

### Fake DATA Generating Process

We started by creating 3 fake binary item response datasets using the Two Parameter Logistic IRT Model

$$P(U_{ij}=1 | \theta_i, d_j, \alpha_j) = \frac{e^{\alpha_j ' \theta_i + d_j}}{1 + e^{\alpha_j ' \theta_i + d_j}}$$ where $U_{ij}$ is the indicator whether student $i$ can answer question $j$ correctly, $\theta_i \in \mathbb R^{K}$ is student's latent trait, $\alpha_j' \in \mathbb R^{K}$ is the discrimination term (factor loading), and $d_j$ is item-wise intercepts (difficulty).

Data is generated by assuming:

-   $\theta_i \sim N(0, I_k)$
-   $\alpha_j \sim N(1, I_k)$: we can randomly set certain component of alphas to be zero, to test whether the SS-IBP prior can successfully select the correct loadings for each item (more on this below)
-   $d_j \sim N(0, 1.5^2)$

### Fake Datasets Considered

We generated 3 datasets, each with 10,000 responses and 40 items.

-   **Dataset 1**: Assume there are 2 factors, each item loads only one factor. This is done by randomly choosing one component of $\alpha_j \in \mathbb R^2$ to be 0.
-   **Dataset 2**: Assume there are 3 factors, each item loads two factors. This is done by randomly choosing one component of $\alpha_j \in \mathbb R^3$ to be 0.
-   **Dateset 3**: Assume there are 3 factors, each item loads only one factor. This is done by randomly choosing two components of $\alpha_j \in \mathbb R^3$ to be 0.

### Factor Loading Visualization (B)

For all the datasets below, I ran the factor rotate code with truncation level $K=4$.

-   Left plot: True alpha values used to generate the fake data
-   Middle plot: Estimated alpha values using the standard IRT package
- Right plot: Estimated beta values using the factor rotation code

```{r, echo=FALSE}
true_filenames <- c("true_alphas_ds1.feather","true_alphas_ds2.feather", "true_alphas_ds3.feather")
true_alphas <- true_filenames %>%
  set_names(.,.) %>%
  map(function(.x) arrow::read_feather(.x))

irt_filenames <- c("dataset1_2factor_alphas.txt", "dataset2_3factor_alphas.txt", "dataset3_3factor_alphas.txt")
irt_alphas <- irt_filenames %>%
  set_names(.,.) %>%
  map(function(.x) as.matrix(read.table(.x)))

ibp_filenames <- c("dataset1_ibp_B.txt", "dataset2_ibp_B.txt", "dataset3_ibp_B.txt")
ibp_alphas <- ibp_filenames %>%
  set_names(.,.) %>%
  map(function(.x) as.matrix(read.table(.x)))

```

#### DataSet 1

In the plots below, each row corresponds to an item, and each column corresponds to the factor loadings: $\alpha_j$ for IRT, and $B_j$ in the SS-IBP context. The scales of $\alpha$ and $B$ are different, since I fit the item response directly to the program and didn't apply sigmoid functions to $B$.

Recall fake dataset 1 has 2 factors in it, and each item can load for up to 1 factor. 

- Note 1: the standard 2-factor MIRT models can mostly recover the true alphas used to generate the fake Dataset.
- Note 2: SS-IBP are able to detect at most one factor is being loaded for each item. But it doesn't seem to suggest there are two factors in total. I suspect the reasons are (1) the factor loading for fake dataset 1 is too sparse and (2) factor rotate strongly prefers more sparse model. 

```{r, f1, fig.show="hold", out.width="66.66%", echo = FALSE}
par(mfrow=c(1,3), mar=c(5.1, 4.1, 4.1, 4.1))
plot(as.matrix(true_alphas$true_alphas_ds1.feather), main="True factor loading")
plot(as.matrix(irt_alphas$dataset1_2factor_alphas.txt), main="2-Factor MIRT Alpha")
plot(as.matrix(ibp_alphas$dataset1_ibp_B.txt), main="SS-IBP")
```

#### DataSet 2

Recall dataset 2 has 3 factors, and each item can load up to 2 factors.

- Note the SS-IBP model has recovered the number of factors to be 3, as the last column are all zeros. The factor loadings produced by SS-IBP are again more sparse than the one produced by 3-factor MIRT, as the middle column rarely plays a role. This is reasonable as each item can load upto 2 factors.

```{r, f2, fig.show="hold", out.width="66.66%", echo=FALSE}
par(mfrow=c(1,3), mar=c(5.1, 4.1, 4.1, 4.1))
plot(as.matrix(true_alphas$true_alphas_ds2.feather), main="True factor loading")
plot(as.matrix(irt_alphas$dataset2_3factor_alphas.txt), main="3-Factor MIRT Alpha")
plot(as.matrix(ibp_alphas$dataset2_ibp_B.txt), main="SS-IBP")
```

#### DataSet 3

Recall data set 3 has 3 factors, but each item may load up to 1 factor.

- Similar observations as in dataset 1. SS-IBP prefers a more sparse latent representation: the model suggests there are only two latent factors involved, and each item may only load for up to one factor.

```{r, f3, fig.show="hold", out.width="66.66%", echo= FALSE}
par(mfrow=c(1,3), mar=c(5.1, 4.1, 4.1, 4.1))
plot(as.matrix(true_alphas$true_alphas_ds3.feather), main="True factor loading")
plot(as.matrix(irt_alphas$dataset3_3factor_alphas.txt), main="3-Factor MIRT Alpha")
plot(as.matrix(ibp_alphas$dataset3_ibp_B.txt), main="SS-IBP")
```


### In-sample Goodness-of-Fit

Note the MSE of SS-IBP model is slightly higher than single-factor IRT model, and much higher than the other MIRT models. This is expected because:

- The data generating process is defined by the equations of an MIRT models, rather than from the exact frameworks of the SS-IBP model.
- I simply fit our data using the factor rotate code, without applying sigmoid function or truncation. 

```{r, echo=FALSE, results= "asis"}
mse_table <- data.frame("IRT" = c(0.1616661, 0.1635147, 0.168824),                     
                    "2-factor" = c(0.1416378, 0.1461116, 0.1555878),
                    "3-factor" = c(0.140939, 0.129212, 0.1460538),
                    "4-factor" = c(0.1394634, 0.1283017, 0.1454276),
                    "SS-IBP" = c(0.1649493, 0.1647031, 0.1752676))
row.names(mse_table) <- c("dataset1", "dataset2", "dataset3")
kable(mse_table, caption = "In-sample MSE")

```

## Experiment on Real Data

Sample 10,000 students responses in Massachusetts Grade 10 Mathematics Exam in 2018. There are 36 multiple choice questions in total.

The results below seem to suggest there is only factor involved for our data, which may not be interesting enough to apply for SS-IBP prior.

```{r, echo=FALSE, results= "asis"}
ll_table <- data.frame("IRT" = c(0.1407343),                     
                    "2-factor" = c(0.1451045),
                    "3-factor" = c(0.1434692),
                    "4-factor" = c(0.1420429),
                    "SS-IBP" = c(0.1498324))
row.names(ll_table) <- c("MSE")
kable(ll_table, caption= "In-sample MSE")
```

```{r, echo=FALSE}
irt_filenames <- c("real_dataset_1alphas.txt", "real_dataset_2alphas.txt", "real_dataset_3alphas.txt")
irt_alphas <- irt_filenames %>%
  set_names(.,.) %>%
  map(function(.x) as.matrix(read.table(.x)))

idp_alphas<- as.matrix(read.table("real_ibp_B.txt"))


```


```{r, r1, fig.show="hold", out.width="66.66%", echo=FALSE}
par(mfrow=c(1,3), mar=c(5.1, 4.1, 4.1, 4.1))
plot(as.matrix(irt_alphas$real_dataset_1alphas.txt), main="IRT Alpha")
plot(as.matrix(irt_alphas$real_dataset_2alphas.txt), main="2-Factor MIRT Alpha")
plot(as.matrix(idp_alphas), main="SS-IBP Loading")
```
